<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="file:///C:/Users/bois/AppData/Local/Pandoc/css/scholmd-heuristically-latest.min.css">
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="vers-un-outil-daide-à-la-décision-plan-chapitre-3">Vers un outil d’aide à la décision : Plan chapitre 3</h1>
<h2 id="introduction-du-chapitre">Introduction du chapitre</h2>
<h2 id="choix-dune-méthodologie-adaptée">Choix d’une méthodologie adaptée</h2>
<h3 id="méthodologies-existantes">1) Méthodologies existantes</h3>
<ul>
<li>Formulation
<ul>
<li>Définition des objectifs</li>
<li>Introduction des type de variables (discrètes, continues, qualitatives)</li>
<li>Definition des contraintes</li>
</ul></li>
<li>Différentes approches
<ul>
<li>Optimisation puis décision (à posteriori)</li>
<li>Décision puis optimisation (à priori –&gt; agrégation)</li>
<li>Décision + Optimisation (combinée, itératif)</li>
</ul></li>
<li>Bilan et sélection d’une approche</li>
</ul>
<p><em>Armand-Decker2015</em>, <em>Rivallain2013</em></p>
<p><br/></p>
<h3 id="les-méthodes-doptimisation-pour-les-problèmes-mixtes">2) Les méthodes d’optimisation pour les problèmes mixtes</h3>
<h4 id="loptimisation-multi-objectif">L’optimisation multi-objectif</h4>
<ul>
<li>Définition et définition
<ul>
<li>Optimisation</li>
<li>Dominance</li>
<li>Front de Pareto</li>
<li>Points de référence</li>
<li>Convexité</li>
</ul></li>
<li>Description des approches existantes
<ul>
<li>Méthodes continues
<ul>
<li>Impossible avec variables discrètes</li>
<li>Nécessite d’être dérivable, d’utiliser un gradient</li>
</ul></li>
<li>Méthodes exactes
<ul>
<li>Problème de cardinalité</li>
<li>Limiter par le temps de simulation</li>
</ul></li>
<li>Méthodes utilisant un heuristic
<ul>
<li>Spécialisés</li>
<li>Parallel</li>
<li>Meta</li>
</ul></li>
<li>Arbre des méthodes pour le bilan</li>
<li>Sélection d’une méthode adaptée</li>
</ul></li>
</ul>
<p><em>Basseur200639</em>, <em>Armand-Decker2015</em>, <em>Rivallain2013</em></p>
<h4 id="les-méta-heuristiques">Les Méta-heuristiques</h4>
<p><em>Généralités</em></p>
<ul>
<li>Définition, différence heuristique et méta-heuristique, utilité, limites, …</li>
<li>Introduire intelligence artificielle</li>
<li>Décrire existant : Évolutionnaires / Essaim / Autres</li>
<li>Comment choisir ? Nombre de paramètres / Applicabilité / Subjectivité</li>
</ul>
<p><em>Approches basées sur les essaims</em></p>
<ul>
<li>Décrire les caractéristiques des essaims</li>
<li>Décrire les différents algorithmes existants avec des applications</li>
</ul>
<p><em>Aboul-EllaHassanien2015</em>, <em>Bonabeau1999</em>, <em>optimisation-multiobjectif_2002</em></p>
<p><br/></p>
<h3 id="réduire-la-cardinalité-du-problème">3) Réduire la cardinalité du problème</h3>
<h4 id="principe-de-lanalyse-de-sensibilité">Principe de l’analyse de sensibilité</h4>
<ul>
<li>Définir l’ensemble des facteurs influents à priori et les objectifs</li>
<li>Limiter la variation en fonction des objectifs</li>
<li>Décrire méthodes existantes :
<ul>
<li>Quand les utiliser ?</li>
<li>Quels limites ?</li>
</ul></li>
</ul>
<h4 id="méthode-de-criblage-morris">Méthode de criblage : Morris</h4>
<ul>
<li>Décrire principe</li>
<li>Décrire améliorations</li>
<li>Limites (variables continues)</li>
</ul>
<p><em>Iooss2011</em>, <em>Saltelli2004</em>, <em>Campolongo199975</em></p>
<h2 id="construction-dun-méta-heuristique">Construction d’un Méta-heuristique</h2>
<h3 id="générateur-de-solutions">1) Générateur de solutions</h3>
<h4 id="motivations">Motivations</h4>
<ul>
<li>Nécessite peu de paramètre à tuner</li>
<li>Respecte les règles caractéristiques des essaims</li>
<li>Simplicité de fonctionnement / implémentation</li>
<li>Équilibre entre exploitation et exploration</li>
<li>Capacité à s’extraire des optimums locaux</li>
<li>Limiter le nombre d’évaluations nécessaires (vitesse de convergence)</li>
<li>Irace package pour initialiser le meta-heuristique</li>
</ul>
<h4 id="artificial-bee-colony-abc">Artificial Bee Colony (ABC)</h4>
<ul>
<li>Décrire son histoire</li>
<li>Décrire le fonctionnement de l’algorithme
<ul>
<li>Les phases (exploitation / recherche locale / exploration)</li>
<li>L’apprentissage par la mise en commun</li>
<li>Recherche stochastique</li>
<li>Sélection par roulette (vs proportionelle, rang, …)</li>
</ul></li>
<li>Extension aux problèmes multi-objectif</li>
<li>Améliorations
<ul>
<li>Existantes</li>
<li>Vol de Lévy pour les Scouts (<em>Mantegna19944677</em>)</li>
<li>Apprentissage par vecteur opposés pour l’initialisation (<em>Tizhoosh2005695</em>)</li>
</ul></li>
<li>(Faire propagande avec des articles montrant qu’il se comporte mieux !)</li>
</ul>
<p><em>Camazine1991547</em>, <em>Akbari201239</em>, <em>Karaboga2005</em></p>
<p><br/></p>
<h3 id="stockage-des-solutions-optimales">2) Stockage des solutions optimales</h3>
<h4 id="motivations-1">Motivations</h4>
<ul>
<li>Garder en mémoire l’évolution du front (multi-objectif)</li>
<li>Assurer l’élitisme</li>
<li>Fournir une base d’apprentissage (mémoire) pour progresser dans la recherche</li>
<li>Éviter la redondance</li>
<li>Assurer la convergence</li>
</ul>
<h4 id="epsilon-archive-epsilon-archive">Epsilon-Archive (<span class="math inline">\(\epsilon\)</span>-archive)</h4>
<ul>
<li>Introduire les techniques de convergence (Dominance rank, Dominance depth, Dominance account)</li>
<li>Introduire les techniques de diversité existantes (Kernel, nearest, hist)</li>
<li>Décrire le fonctionnement de cette approche</li>
<li>Comparer avec les autres approches existantes
<ul>
<li>Mettre en exergue l’élitisme nécessaire à la convergence</li>
<li>Mettre en exergue la rapidité de l’approche</li>
<li>Mettre en exergue la diversité qu’il apporte</li>
<li>Mettre en exergue la robustesse lorsque le nombre d’objectif augmente</li>
<li>Réduction du problème de redondance</li>
</ul></li>
</ul>
<p><em>Laumanns2002263</em>, <em>Deb2005501</em> <em>37</em>, <em>47</em>, <em>141</em></p>
<p><br/></p>
<h3 id="prendre-en-compte-les-contraintes">3) Prendre en compte les contraintes</h3>
<ul>
<li>Décrire les méthodes existantes
<ul>
<li>Pénalité (diverses approches avec des poids)</li>
<li>Exclusion (ne considère pas du tout les solutions sous contraintes)</li>
<li>Deb rules (priorité aux solutions respectant les contraintes)</li>
</ul></li>
<li>Décrire la méthode retenue
<ul>
<li>Accepte des solutions avec contraintes</li>
<li>Permet d’explorer des espaces contraints</li>
<li>Capacité à contrôler / limiter le nombre de solution sous contraintes</li>
</ul></li>
<li>Cas spécifique de l’archivage
<ul>
<li>Comportement stricte pour les solutions dans l’archive</li>
<li>Conserver que des solutions possibles / voulues / plausibles</li>
</ul></li>
</ul>
<p><em>Woldesenbet20073077</em>, <em>Deb2000311</em></p>
<p><br/></p>
<h3 id="description-globale-du-méta-heuristique">4) Description globale du Méta-heuristique</h3>
<ul>
<li>Décrire algorithme graphiquement (fonctionnement global)</li>
<li>Décrire implémentation (rapide)
<ul>
<li>Description macro de l’architecture</li>
<li>Choix de la parallélisation des évaluations
<ul>
<li>Temps de simulation grand (temps création thread non impactant)</li>
<li>Temps de simulation cours (temps création thread impactant)</li>
</ul></li>
<li>Lien vers bibliothèque : pyMOABC</li>
</ul></li>
<li>Validation
<ul>
<li>Benchmark importants (Autres en annexes)</li>
<li>Autres algorithmes</li>
</ul></li>
</ul>
<p><em>Deb2005105</em>, <em>Zitzler2000173</em></p>
<h2 id="que-retenir">Que retenir ?</h2>
<ul>
<li>Faire un récapitulatif</li>
<li>Ouvrir le prochain chapitre</li>
</ul>
</body>
</html>
